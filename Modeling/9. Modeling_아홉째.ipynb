{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51d5b863-281b-48df-a1c3-e6eb7ef998a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import math\n",
    "\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from time import sleep\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1022001c-571d-4bea-bc97-03d3c9dabb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision import transforms, utils\n",
    "from torchvision.transforms import Resize, ToTensor, Normalize\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, SubsetRandomSampler, WeightedRandomSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9d39a9-61ce-4963-9b63-a4221f04fc6c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Make Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f6b5a51-e5df-47b3-8ba5-e113e3dd94ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>path</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>stem</th>\n",
       "      <th>img_path</th>\n",
       "      <th>gender_issue</th>\n",
       "      <th>mask_issue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000001</td>\n",
       "      <td>000001_female_Asian_45</td>\n",
       "      <td>45</td>\n",
       "      <td>female</td>\n",
       "      <td>mask1</td>\n",
       "      <td>/opt/ml/input/data/train/images/000001_female_...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000001</td>\n",
       "      <td>000001_female_Asian_45</td>\n",
       "      <td>45</td>\n",
       "      <td>female</td>\n",
       "      <td>mask2</td>\n",
       "      <td>/opt/ml/input/data/train/images/000001_female_...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000001</td>\n",
       "      <td>000001_female_Asian_45</td>\n",
       "      <td>45</td>\n",
       "      <td>female</td>\n",
       "      <td>mask4</td>\n",
       "      <td>/opt/ml/input/data/train/images/000001_female_...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000001</td>\n",
       "      <td>000001_female_Asian_45</td>\n",
       "      <td>45</td>\n",
       "      <td>female</td>\n",
       "      <td>mask3</td>\n",
       "      <td>/opt/ml/input/data/train/images/000001_female_...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000001</td>\n",
       "      <td>000001_female_Asian_45</td>\n",
       "      <td>45</td>\n",
       "      <td>female</td>\n",
       "      <td>incorrect_mask</td>\n",
       "      <td>/opt/ml/input/data/train/images/000001_female_...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                    path  age  gender            stem  \\\n",
       "0  000001  000001_female_Asian_45   45  female           mask1   \n",
       "1  000001  000001_female_Asian_45   45  female           mask2   \n",
       "2  000001  000001_female_Asian_45   45  female           mask4   \n",
       "3  000001  000001_female_Asian_45   45  female           mask3   \n",
       "4  000001  000001_female_Asian_45   45  female  incorrect_mask   \n",
       "\n",
       "                                            img_path  gender_issue  mask_issue  \n",
       "0  /opt/ml/input/data/train/images/000001_female_...         False       False  \n",
       "1  /opt/ml/input/data/train/images/000001_female_...         False       False  \n",
       "2  /opt/ml/input/data/train/images/000001_female_...         False       False  \n",
       "3  /opt/ml/input/data/train/images/000001_female_...         False       False  \n",
       "4  /opt/ml/input/data/train/images/000001_female_...         False       False  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/opt/ml/code/data/Final.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "786cc7d2-f4dd-47ef-b60e-7c1014bd7edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'] = ''\n",
    "for i in range(len(df)) :\n",
    "    label = 0\n",
    "    # 나이를 기준으로 점수\n",
    "    if df['age'][i] < 30 :\n",
    "        label = 0\n",
    "    elif 30 <= df['age'][i] < 60 :\n",
    "        label = 1\n",
    "    elif 60 <= df['age'][i] :\n",
    "        label = 2\n",
    "    \n",
    "    # 여자일 경우 남자의 label +3\n",
    "    if df['gender'][i] == 'female' :\n",
    "        label += 3\n",
    "    \n",
    "    # mask상태가 Not wear일 경우 + 12, Incorrect일 경우 + 6\n",
    "    if df['stem'][i] == 'normal' :\n",
    "        label += 12\n",
    "    elif df['stem'][i] == 'incorrect_mask' :\n",
    "        label += 6\n",
    "    \n",
    "    df['label'][i] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b63a8097-52d6-4928-a438-0c8443462145",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>path</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>stem</th>\n",
       "      <th>img_path</th>\n",
       "      <th>gender_issue</th>\n",
       "      <th>mask_issue</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9711</th>\n",
       "      <td>003421</td>\n",
       "      <td>003421_female_Asian_38</td>\n",
       "      <td>38</td>\n",
       "      <td>female</td>\n",
       "      <td>mask4</td>\n",
       "      <td>/opt/ml/input/data/train/images/003421_female_...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13655</th>\n",
       "      <td>004481</td>\n",
       "      <td>004481_male_Asian_29</td>\n",
       "      <td>29</td>\n",
       "      <td>male</td>\n",
       "      <td>mask5</td>\n",
       "      <td>/opt/ml/input/data/train/images/004481_male_As...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3922</th>\n",
       "      <td>001188</td>\n",
       "      <td>001188_male_Asian_60</td>\n",
       "      <td>60</td>\n",
       "      <td>male</td>\n",
       "      <td>mask4</td>\n",
       "      <td>/opt/ml/input/data/train/images/001188_male_As...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6775</th>\n",
       "      <td>001759</td>\n",
       "      <td>001759_female_Asian_46</td>\n",
       "      <td>46</td>\n",
       "      <td>female</td>\n",
       "      <td>normal</td>\n",
       "      <td>/opt/ml/input/data/train/images/001759_female_...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12722</th>\n",
       "      <td>004281</td>\n",
       "      <td>004281_female_Asian_60</td>\n",
       "      <td>60</td>\n",
       "      <td>female</td>\n",
       "      <td>mask3</td>\n",
       "      <td>/opt/ml/input/data/train/images/004281_female_...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12031</th>\n",
       "      <td>003981</td>\n",
       "      <td>003981_male_Asian_60</td>\n",
       "      <td>60</td>\n",
       "      <td>male</td>\n",
       "      <td>mask5</td>\n",
       "      <td>/opt/ml/input/data/train/images/003981_male_As...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7674</th>\n",
       "      <td>003032</td>\n",
       "      <td>003032_female_Asian_20</td>\n",
       "      <td>20</td>\n",
       "      <td>female</td>\n",
       "      <td>mask4</td>\n",
       "      <td>/opt/ml/input/data/train/images/003032_female_...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18077</th>\n",
       "      <td>006622</td>\n",
       "      <td>006622_male_Asian_19</td>\n",
       "      <td>19</td>\n",
       "      <td>male</td>\n",
       "      <td>incorrect_mask</td>\n",
       "      <td>/opt/ml/input/data/train/images/006622_male_As...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17895</th>\n",
       "      <td>006571</td>\n",
       "      <td>006571_female_Asian_21</td>\n",
       "      <td>21</td>\n",
       "      <td>female</td>\n",
       "      <td>mask3</td>\n",
       "      <td>/opt/ml/input/data/train/images/006571_female_...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9192</th>\n",
       "      <td>003332</td>\n",
       "      <td>003332_female_Asian_19</td>\n",
       "      <td>19</td>\n",
       "      <td>female</td>\n",
       "      <td>mask2</td>\n",
       "      <td>/opt/ml/input/data/train/images/003332_female_...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                    path  age  gender            stem  \\\n",
       "9711   003421  003421_female_Asian_38   38  female           mask4   \n",
       "13655  004481    004481_male_Asian_29   29    male           mask5   \n",
       "3922   001188    001188_male_Asian_60   60    male           mask4   \n",
       "6775   001759  001759_female_Asian_46   46  female          normal   \n",
       "12722  004281  004281_female_Asian_60   60  female           mask3   \n",
       "12031  003981    003981_male_Asian_60   60    male           mask5   \n",
       "7674   003032  003032_female_Asian_20   20  female           mask4   \n",
       "18077  006622    006622_male_Asian_19   19    male  incorrect_mask   \n",
       "17895  006571  006571_female_Asian_21   21  female           mask3   \n",
       "9192   003332  003332_female_Asian_19   19  female           mask2   \n",
       "\n",
       "                                                img_path  gender_issue  \\\n",
       "9711   /opt/ml/input/data/train/images/003421_female_...         False   \n",
       "13655  /opt/ml/input/data/train/images/004481_male_As...         False   \n",
       "3922   /opt/ml/input/data/train/images/001188_male_As...         False   \n",
       "6775   /opt/ml/input/data/train/images/001759_female_...         False   \n",
       "12722  /opt/ml/input/data/train/images/004281_female_...         False   \n",
       "12031  /opt/ml/input/data/train/images/003981_male_As...         False   \n",
       "7674   /opt/ml/input/data/train/images/003032_female_...         False   \n",
       "18077  /opt/ml/input/data/train/images/006622_male_As...         False   \n",
       "17895  /opt/ml/input/data/train/images/006571_female_...         False   \n",
       "9192   /opt/ml/input/data/train/images/003332_female_...         False   \n",
       "\n",
       "       mask_issue label  \n",
       "9711        False     4  \n",
       "13655       False     0  \n",
       "3922        False     2  \n",
       "6775        False    16  \n",
       "12722       False     5  \n",
       "12031       False     2  \n",
       "7674        False     3  \n",
       "18077       False     6  \n",
       "17895       False     3  \n",
       "9192        False     3  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04d3539-9893-490b-88a3-d8083276ed09",
   "metadata": {},
   "source": [
    "## Dataset Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b646f34-b295-43f8-85fa-6ae3478e46e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskDataset(Dataset) :\n",
    "    def __init__(self, path_list, label_list, transform, train = True) :\n",
    "        self.train = train\n",
    "        if self.train :\n",
    "            self.X = []\n",
    "            self.y = []\n",
    "            for path, label in zip(path_list, label_list) :\n",
    "                image = Image.open(path)\n",
    "                self.X.append(image)\n",
    "                self.y.append(label)\n",
    "        else :\n",
    "            self.X = []\n",
    "            for path in path_list :\n",
    "                image = Image.open(path)\n",
    "                self.X.append(image)\n",
    "        \n",
    "        self.transform = transform\n",
    "        self._repr_indent = 4\n",
    "        if self.train :\n",
    "            self.classes = list(set(self.y))\n",
    "    \n",
    "    def __len__(self) :\n",
    "        len_dataset = len(self.X)\n",
    "        return len_dataset\n",
    "\n",
    "    def __getitem__(self, idx) :\n",
    "        X = self.X[idx]\n",
    "        X = self.transform(X)\n",
    "        if not self.train :\n",
    "            y = None\n",
    "        else :\n",
    "            y = self.y[idx]\n",
    "        return torch.tensor(X, dtype = torch.float), torch.tensor(y, dtype = torch.long)\n",
    "    \n",
    "    def __repr__(self) :\n",
    "        head = \"(PyTorch Practice) My Custom Dataset : MASK\"\n",
    "        num_data = self._repr_indent*\" \" + \"Number of datapoints : {}\".format(self.__len__())\n",
    "        \n",
    "        if self.train :\n",
    "            num_classes = self._repr_indent*\" \" + \"Number of classes {}\".format(len(self.classes))\n",
    "        else :\n",
    "            num_classes = self._repr_indent*\" \" + \"Number of classes None\"\n",
    "            \n",
    "        return '\\n'.join([head, num_data, num_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4888f394-2051-464c-a424-47ef87896ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = df['img_path']\n",
    "target = list(df['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245eca63-6041-4d15-95c4-c910037c12ed",
   "metadata": {},
   "source": [
    "### ResNext50_32x4d학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9759b413-d65d-42f7-9c4a-daff5896ff93",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.resnext50_32x4d(pretrained=True)\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Linear(2048, 1024, bias = True),\n",
    "    nn.ReLU(inplace = True),\n",
    "    nn.Dropout(p = 0.3),\n",
    "    nn.Linear(1024, 256, bias = True),\n",
    "    nn.ReLU(inplace = True),\n",
    "    nn.Dropout(p = 0.3),\n",
    "    nn.Linear(256, 18, bias = True))\n",
    "\n",
    "torch.nn.init.xavier_uniform_(model.fc[0].weight)\n",
    "stdv = 1.0 / np.sqrt(model.fc[0].in_features)\n",
    "model.fc[0].bias.data.uniform_(-stdv,stdv)\n",
    "\n",
    "for param in model.parameters() : # frozon 해제\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d597e24b-efc1-4cb0-ba50-5de16bf35415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "cuda:0 is using !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 222/222 [05:03<00:00,  1.37s/it]\n",
      "  0%|          | 0/74 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 epoch-0의 train-데이터 셋에서 평균 Loss : 0.3193, 평균 Accuracy : 0.6423, 평균 F1 Score :  0.3221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [00:49<00:00,  1.50it/s]\n",
      "  0%|          | 0/222 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 epoch-0의 test-데이터 셋에서 평균 Loss : 0.1103, 평균 Accuracy : 0.8777, 평균 F1 Score :  0.6763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 222/222 [04:20<00:00,  1.17s/it]\n",
      "  0%|          | 0/74 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 epoch-1의 train-데이터 셋에서 평균 Loss : 0.0689, 평균 Accuracy : 0.9256, 평균 F1 Score :  0.7855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [00:34<00:00,  2.14it/s]\n",
      "  0%|          | 0/222 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 epoch-1의 test-데이터 셋에서 평균 Loss : 0.0362, 평균 Accuracy : 0.9477, 평균 F1 Score :  0.8325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 222/222 [04:20<00:00,  1.17s/it]\n",
      "  0%|          | 0/74 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 epoch-2의 train-데이터 셋에서 평균 Loss : 0.0226, 평균 Accuracy : 0.9757, 평균 F1 Score :  0.9039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [00:35<00:00,  2.10it/s]\n",
      "  0%|          | 0/222 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 epoch-2의 test-데이터 셋에서 평균 Loss : 0.0187, 평균 Accuracy : 0.9799, 평균 F1 Score :  0.9439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 222/222 [04:20<00:00,  1.17s/it]\n",
      "  0%|          | 0/74 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 epoch-3의 train-데이터 셋에서 평균 Loss : 0.0111, 평균 Accuracy : 0.9874, 평균 F1 Score :  0.9539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [00:35<00:00,  2.10it/s]\n",
      "  0%|          | 0/222 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 epoch-3의 test-데이터 셋에서 평균 Loss : 0.0129, 평균 Accuracy : 0.9839, 평균 F1 Score :  0.9499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 222/222 [04:21<00:00,  1.18s/it]\n",
      "  0%|          | 0/74 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 epoch-4의 train-데이터 셋에서 평균 Loss : 0.0057, 평균 Accuracy : 0.9953, 평균 F1 Score :  0.9848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [00:35<00:00,  2.11it/s]\n",
      "  0%|          | 0/222 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 epoch-4의 test-데이터 셋에서 평균 Loss : 0.0085, 평균 Accuracy : 0.9905, 평균 F1 Score :  0.9720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 222/222 [04:21<00:00,  1.18s/it]\n",
      "  0%|          | 0/74 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 epoch-5의 train-데이터 셋에서 평균 Loss : 0.0038, 평균 Accuracy : 0.9959, 평균 F1 Score :  0.9847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [00:34<00:00,  2.12it/s]\n",
      "  0%|          | 0/222 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 epoch-5의 test-데이터 셋에서 평균 Loss : 0.0113, 평균 Accuracy : 0.9873, 평균 F1 Score :  0.9723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 222/222 [04:20<00:00,  1.17s/it]\n",
      "  0%|          | 0/74 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 epoch-6의 train-데이터 셋에서 평균 Loss : 0.0044, 평균 Accuracy : 0.9946, 평균 F1 Score :  0.9829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [00:35<00:00,  2.08it/s]\n",
      "  0%|          | 0/222 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 epoch-6의 test-데이터 셋에서 평균 Loss : 0.0063, 평균 Accuracy : 0.9930, 평균 F1 Score :  0.9796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 222/222 [04:22<00:00,  1.18s/it]\n",
      "  0%|          | 0/74 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 epoch-7의 train-데이터 셋에서 평균 Loss : 0.0023, 평균 Accuracy : 0.9980, 평균 F1 Score :  0.9946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [00:35<00:00,  2.08it/s]\n",
      "  0%|          | 0/222 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 epoch-7의 test-데이터 셋에서 평균 Loss : 0.0061, 평균 Accuracy : 0.9943, 평균 F1 Score :  0.9862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 222/222 [04:21<00:00,  1.18s/it]\n",
      "  0%|          | 0/74 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 epoch-8의 train-데이터 셋에서 평균 Loss : 0.0022, 평균 Accuracy : 0.9978, 평균 F1 Score :  0.9942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [00:35<00:00,  2.11it/s]\n",
      "  0%|          | 0/222 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 epoch-8의 test-데이터 셋에서 평균 Loss : 0.0076, 평균 Accuracy : 0.9917, 평균 F1 Score :  0.9830\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 222/222 [04:21<00:00,  1.18s/it]\n",
      "  0%|          | 0/74 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 epoch-9의 train-데이터 셋에서 평균 Loss : 0.0028, 평균 Accuracy : 0.9971, 평균 F1 Score :  0.9960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [00:35<00:00,  2.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 epoch-9의 test-데이터 셋에서 평균 Loss : 0.0072, 평균 Accuracy : 0.9920, 평균 F1 Score :  0.9762\n",
      "Fold 2\n",
      "cuda:0 is using !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 222/222 [04:51<00:00,  1.31s/it]\n",
      "  0%|          | 0/74 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 epoch-0의 train-데이터 셋에서 평균 Loss : 0.0061, 평균 Accuracy : 0.9926, 평균 F1 Score :  0.9819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [00:46<00:00,  1.61it/s]\n",
      "  0%|          | 0/222 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 epoch-0의 test-데이터 셋에서 평균 Loss : 0.0004, 평균 Accuracy : 0.9998, 평균 F1 Score :  0.9999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 222/222 [04:22<00:00,  1.18s/it]\n",
      "  0%|          | 0/74 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 epoch-1의 train-데이터 셋에서 평균 Loss : 0.0037, 평균 Accuracy : 0.9959, 평균 F1 Score :  0.9904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [00:35<00:00,  2.08it/s]\n",
      "  0%|          | 0/222 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 epoch-1의 test-데이터 셋에서 평균 Loss : 0.0009, 평균 Accuracy : 0.9987, 평균 F1 Score :  0.9988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 222/222 [04:22<00:00,  1.18s/it]\n",
      "  0%|          | 0/74 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 epoch-2의 train-데이터 셋에서 평균 Loss : 0.0028, 평균 Accuracy : 0.9972, 평균 F1 Score :  0.9928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [00:36<00:00,  2.04it/s]\n",
      "  0%|          | 0/222 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 epoch-2의 test-데이터 셋에서 평균 Loss : 0.0003, 평균 Accuracy : 0.9998, 평균 F1 Score :  0.9998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 222/222 [04:22<00:00,  1.18s/it]\n",
      "  0%|          | 0/74 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 epoch-3의 train-데이터 셋에서 평균 Loss : 0.0022, 평균 Accuracy : 0.9978, 평균 F1 Score :  0.9929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [00:36<00:00,  2.05it/s]\n",
      "  0%|          | 0/222 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 epoch-3의 test-데이터 셋에서 평균 Loss : 0.0008, 평균 Accuracy : 0.9987, 평균 F1 Score :  0.9964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 222/222 [04:22<00:00,  1.18s/it]\n",
      "  0%|          | 0/74 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 epoch-4의 train-데이터 셋에서 평균 Loss : 0.0017, 평균 Accuracy : 0.9982, 평균 F1 Score :  0.9971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [00:36<00:00,  2.05it/s]\n",
      "  0%|          | 0/222 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 epoch-4의 test-데이터 셋에서 평균 Loss : 0.0007, 평균 Accuracy : 0.9992, 평균 F1 Score :  0.9990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 222/222 [04:22<00:00,  1.18s/it]\n",
      "  0%|          | 0/74 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 epoch-5의 train-데이터 셋에서 평균 Loss : 0.0021, 평균 Accuracy : 0.9976, 평균 F1 Score :  0.9939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [00:35<00:00,  2.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopping!\n",
      "fold2 Stopped\n",
      "Fold 3\n",
      "cuda:0 is using !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 222/222 [04:54<00:00,  1.33s/it]\n",
      "  0%|          | 0/74 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 epoch-0의 train-데이터 셋에서 평균 Loss : 0.0034, 평균 Accuracy : 0.9960, 평균 F1 Score :  0.9916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [00:47<00:00,  1.55it/s]\n",
      "  0%|          | 0/222 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 epoch-0의 test-데이터 셋에서 평균 Loss : 0.0029, 평균 Accuracy : 0.9966, 평균 F1 Score :  0.9932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 222/222 [04:20<00:00,  1.17s/it]\n",
      "  0%|          | 0/74 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 epoch-1의 train-데이터 셋에서 평균 Loss : 0.0032, 평균 Accuracy : 0.9961, 평균 F1 Score :  0.9893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [00:35<00:00,  2.11it/s]\n",
      "  0%|          | 0/222 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 epoch-1의 test-데이터 셋에서 평균 Loss : 0.0003, 평균 Accuracy : 0.9998, 평균 F1 Score :  0.9999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 222/222 [04:21<00:00,  1.18s/it]\n",
      "  0%|          | 0/74 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 epoch-2의 train-데이터 셋에서 평균 Loss : 0.0017, 평균 Accuracy : 0.9980, 평균 F1 Score :  0.9967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [00:35<00:00,  2.10it/s]\n",
      "  0%|          | 0/222 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 epoch-2의 test-데이터 셋에서 평균 Loss : 0.0001, 평균 Accuracy : 1.0000, 평균 F1 Score :  1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 222/222 [04:21<00:00,  1.18s/it]\n",
      "  0%|          | 0/74 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 epoch-3의 train-데이터 셋에서 평균 Loss : 0.0014, 평균 Accuracy : 0.9981, 평균 F1 Score :  0.9957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [00:34<00:00,  2.14it/s]\n",
      "  0%|          | 0/222 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 epoch-3의 test-데이터 셋에서 평균 Loss : 0.0002, 평균 Accuracy : 0.9998, 평균 F1 Score :  0.9995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 222/222 [04:19<00:00,  1.17s/it]\n",
      "  0%|          | 0/74 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 epoch-4의 train-데이터 셋에서 평균 Loss : 0.0009, 평균 Accuracy : 0.9989, 평균 F1 Score :  0.9956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [00:34<00:00,  2.14it/s]\n",
      "  0%|          | 0/222 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 epoch-4의 test-데이터 셋에서 평균 Loss : 0.0007, 평균 Accuracy : 0.9989, 평균 F1 Score :  0.9971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 222/222 [04:20<00:00,  1.17s/it]\n",
      "  0%|          | 0/74 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 epoch-5의 train-데이터 셋에서 평균 Loss : 0.0028, 평균 Accuracy : 0.9965, 평균 F1 Score :  0.9900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [00:35<00:00,  2.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopping!\n",
      "fold3 Stopped\n",
      "Fold 4\n",
      "cuda:0 is using !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 222/222 [04:53<00:00,  1.32s/it]\n",
      "  0%|          | 0/74 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 epoch-0의 train-데이터 셋에서 평균 Loss : 0.0021, 평균 Accuracy : 0.9967, 평균 F1 Score :  0.9905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [00:46<00:00,  1.61it/s]\n",
      "  0%|          | 0/222 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 epoch-0의 test-데이터 셋에서 평균 Loss : 0.0005, 평균 Accuracy : 0.9994, 평균 F1 Score :  0.9980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 222/222 [04:19<00:00,  1.17s/it]\n",
      "  0%|          | 0/74 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 epoch-1의 train-데이터 셋에서 평균 Loss : 0.0023, 평균 Accuracy : 0.9974, 평균 F1 Score :  0.9958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [00:34<00:00,  2.14it/s]\n",
      "  0%|          | 0/222 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 epoch-1의 test-데이터 셋에서 평균 Loss : 0.0005, 평균 Accuracy : 0.9996, 평균 F1 Score :  0.9988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 222/222 [04:19<00:00,  1.17s/it]\n",
      "  0%|          | 0/74 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 epoch-2의 train-데이터 셋에서 평균 Loss : 0.0019, 평균 Accuracy : 0.9978, 평균 F1 Score :  0.9962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [00:34<00:00,  2.12it/s]\n",
      "  0%|          | 0/222 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 epoch-2의 test-데이터 셋에서 평균 Loss : 0.0001, 평균 Accuracy : 1.0000, 평균 F1 Score :  1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 222/222 [04:19<00:00,  1.17s/it]\n",
      "  0%|          | 0/74 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 epoch-3의 train-데이터 셋에서 평균 Loss : 0.0021, 평균 Accuracy : 0.9972, 평균 F1 Score :  0.9931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [00:35<00:00,  2.11it/s]\n",
      "  0%|          | 0/222 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 epoch-3의 test-데이터 셋에서 평균 Loss : 0.0005, 평균 Accuracy : 0.9994, 평균 F1 Score :  0.9991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 222/222 [04:20<00:00,  1.17s/it]\n",
      "  0%|          | 0/74 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 epoch-4의 train-데이터 셋에서 평균 Loss : 0.0008, 평균 Accuracy : 0.9990, 평균 F1 Score :  0.9971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [00:34<00:00,  2.12it/s]\n",
      "  0%|          | 0/222 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 epoch-4의 test-데이터 셋에서 평균 Loss : 0.0001, 평균 Accuracy : 0.9996, 평균 F1 Score :  0.9994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 222/222 [04:19<00:00,  1.17s/it]\n",
      "  0%|          | 0/74 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 epoch-5의 train-데이터 셋에서 평균 Loss : 0.0009, 평균 Accuracy : 0.9989, 평균 F1 Score :  0.9977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [00:34<00:00,  2.14it/s]\n",
      "  0%|          | 0/222 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 epoch-5의 test-데이터 셋에서 평균 Loss : 0.0001, 평균 Accuracy : 0.9998, 평균 F1 Score :  0.9996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 222/222 [04:19<00:00,  1.17s/it]\n",
      "  0%|          | 0/74 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 epoch-6의 train-데이터 셋에서 평균 Loss : 0.0010, 평균 Accuracy : 0.9987, 평균 F1 Score :  0.9977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [00:34<00:00,  2.12it/s]\n",
      "  0%|          | 0/222 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 epoch-6의 test-데이터 셋에서 평균 Loss : 0.0003, 평균 Accuracy : 0.9994, 평균 F1 Score :  0.9981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 222/222 [04:18<00:00,  1.16s/it]\n",
      "  0%|          | 0/74 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 epoch-7의 train-데이터 셋에서 평균 Loss : 0.0023, 평균 Accuracy : 0.9972, 평균 F1 Score :  0.9936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [00:34<00:00,  2.15it/s]\n",
      "  0%|          | 0/222 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 epoch-7의 test-데이터 셋에서 평균 Loss : 0.0017, 평균 Accuracy : 0.9979, 평균 F1 Score :  0.9976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 222/222 [04:18<00:00,  1.16s/it]\n",
      "  0%|          | 0/74 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 epoch-8의 train-데이터 셋에서 평균 Loss : 0.0031, 평균 Accuracy : 0.9964, 평균 F1 Score :  0.9919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [00:34<00:00,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopping!\n",
      "fold4 Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "stf = StratifiedKFold(n_splits = 4, shuffle = True, random_state =42)\n",
    "foldperf = {}\n",
    "for fold, (train_idx, valid_idx) in enumerate(stf.split(data_path, target)) :\n",
    "    \n",
    "    print('Fold {}'.format(fold + 1))\n",
    "    target_array = np.array(target)\n",
    "    \n",
    "    dataset_train_Mask = MaskDataset(path_list = data_path[train_idx],\n",
    "                                     label_list = target_array[train_idx],\n",
    "                                     transform = transforms.Compose([\n",
    "                                         Resize((512, 384), Image.BILINEAR),\n",
    "                                         ToTensor(),\n",
    "                                         Normalize(mean = (0.5,0.5,0.5), std = (0.2, 0.2, 0.2)),\n",
    "                                      ]),\n",
    "                                      train = True,\n",
    "                                      )\n",
    "    dataset_valid_Mask = MaskDataset(path_list = data_path[valid_idx],\n",
    "                                     label_list = target_array[valid_idx],\n",
    "                                     transform = transforms.Compose([\n",
    "                                          Resize((512, 384), Image.BILINEAR),\n",
    "                                          ToTensor(),\n",
    "                                          Normalize(mean = (0.5,0.5,0.5), std = (0.2, 0.2, 0.2)),\n",
    "                                      ]),\n",
    "                                      train = True,\n",
    "                                      )\n",
    "    BATCH_SIZE = 64\n",
    "    mask_train_dataloader = torch.utils.data.DataLoader(dataset_train_Mask,\n",
    "                                                        batch_size = BATCH_SIZE,\n",
    "                                                        shuffle = True)\n",
    "    mask_valid_dataloader = torch.utils.data.DataLoader(dataset_valid_Mask,\n",
    "                                                        batch_size = BATCH_SIZE,\n",
    "                                                        shuffle = True)\n",
    "    \n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f'{device} is using !')\n",
    "    sleep(1)\n",
    "    \n",
    "    model = model.to(device)\n",
    "\n",
    "    LEARNING_RATE = 0.0001\n",
    "    #NUM_EPOCH = 100\n",
    "\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = LEARNING_RATE)\n",
    "\n",
    "    dataloaders = {\n",
    "        'train' : mask_train_dataloader,\n",
    "        'test' : mask_valid_dataloader\n",
    "    }\n",
    "    \n",
    "    history = {'train_loss' : [], 'test_loss' : [],\n",
    "               'train_acc' : [], 'test_acc' : [],\n",
    "               'train_f1' : [], 'test_f1' : []}\n",
    "    \n",
    "    n_epochs_stop = 3\n",
    "    epochs_no_improve = 0\n",
    "    early_stop = False\n",
    "    min_val_loss = np.Inf\n",
    "    NUM_ACCUM = 4\n",
    "    \n",
    "    best_test_accuracy = 0\n",
    "    best_test_loss = 9999.\n",
    "    for epoch in range(10) :\n",
    "        for phase in ['train', 'test'] :\n",
    "            running_loss = 0.\n",
    "            running_acc = 0.\n",
    "            running_f1 = 0.\n",
    "            n_iter = 0\n",
    "            \n",
    "            if phase == 'train' :\n",
    "                model.train()\n",
    "            elif phase == 'test' :\n",
    "                model.eval()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            for ind, (images, labels) in enumerate(tqdm(dataloaders[phase])) :\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train') : # phase == 'train'일 경우에만 grad_enabled를 True\n",
    "                    logits = model(images)\n",
    "                    _, preds = torch.max(logits, 1)\n",
    "                    loss = loss_fn(logits, labels) / NUM_ACCUM\n",
    "                    \n",
    "                    if phase == 'train' :\n",
    "                        loss.backward()\n",
    "                        \n",
    "                        if ind % NUM_ACCUM == 0 :\n",
    "                            optimizer.step()\n",
    "                            optimizer.zero_grad()\n",
    "\n",
    "                running_loss += loss.item() * images.size(0)\n",
    "                running_acc += torch.sum(preds == labels.data)\n",
    "                running_f1 += f1_score(preds.cpu().numpy(), labels.cpu().numpy(), average = 'macro')\n",
    "                n_iter += 1\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_acc / len(dataloaders[phase].dataset)\n",
    "            epoch_f1 = running_f1 / n_iter\n",
    "            #epoch_f1_check = running_f1 / len(dataloaders[phase].dataset)\n",
    "            #print('n_iter는 ', n_iter, ' dataset는 :', len(dataloaders[phase].dataset))\n",
    "            #print('n_iter :', epoch_f1, ' dataset :', epoch_f1_check)\n",
    "            \n",
    "            if phase == 'test' :\n",
    "                if epoch_loss < min_val_loss :\n",
    "                    epochs_no_improve = 0\n",
    "                    min_val_loss = epoch_loss\n",
    "                else :\n",
    "                    epochs_no_improve += 1\n",
    "                \n",
    "                if epochs_no_improve == n_epochs_stop :\n",
    "                    print('Early Stopping!')\n",
    "                    early_stop = True\n",
    "                    break\n",
    "            \n",
    "            if phase == 'train' :\n",
    "                history['train_loss'].append(epoch_loss)\n",
    "                history['train_acc'].append(epoch_acc)\n",
    "                history['train_f1'].append(epoch_f1)\n",
    "            elif phase == 'test' :\n",
    "                history['test_loss'].append(epoch_loss)\n",
    "                history['test_acc'].append(epoch_acc)\n",
    "                history['test_f1'].append(epoch_f1)\n",
    "\n",
    "            print(f\"현재 epoch-{epoch}의 {phase}-데이터 셋에서 평균 Loss : {epoch_loss:.4f}, 평균 Accuracy : {epoch_acc:.4f}, 평균 F1 Score : {epoch_f1: .4f}\")\n",
    "            #if phase == \"test\" and best_test_accuracy < epoch_acc: # phase가 test일 때, best accuracy 계산\n",
    "            #    best_test_accuracy = epoch_acc\n",
    "            #if phase == \"test\" and best_test_loss > epoch_loss: # phase가 test일 때, best loss 계산\n",
    "            #    best_test_loss = epoch_loss\n",
    "    \n",
    "        if early_stop :\n",
    "            print(f'fold{fold+1} Stopped')\n",
    "            break\n",
    "    foldperf['fold{}'.format(fold+1)] = history \n",
    "    \n",
    "    #print(\"학습 종료!\")\n",
    "    #print(f\"최고 accuracy : {best_test_accuracy}, 최고 낮은 loss : {best_test_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3d4c3f54-6400-4772-a833-0608a34922bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, '/opt/ml/code/model/Resnext50_32x4d-SKFold4-10-EarlyStopping-Accumulation.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3cf95d56-229f-49a0-8ad3-d4f52db3fd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 데이터셋 폴더 경로를 지정해주세요.\n",
    "test_dir = '/opt/ml/input/data/eval'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d60a301d-abc9-45a1-a3d5-c389c53b28b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# meta 데이터와 이미지 경로를 불러옵니다.\n",
    "submission = pd.read_csv(os.path.join(test_dir, 'info.csv'))\n",
    "image_dir = os.path.join(test_dir, 'images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e4f35cc8-5c45-4fdd-8bd4-f45b7084488c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, img_paths, transform):\n",
    "        self.img_paths = img_paths\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = Image.open(self.img_paths[index])\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9d1bbfa8-254a-425f-8fe2-c8dfb9de46be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Dataset 클래스 객체를 생성하고 DataLoader를 만듭니다.\n",
    "image_paths = [os.path.join(image_dir, img_id) for img_id in submission.ImageID]\n",
    "transform = transforms.Compose([\n",
    "    Resize((512, 384), Image.BILINEAR),\n",
    "    ToTensor(),\n",
    "    Normalize(mean=(0.5, 0.5, 0.5), std=(0.2, 0.2, 0.2)),\n",
    "])\n",
    "dataset = TestDataset(image_paths, transform)\n",
    "\n",
    "loader = DataLoader(\n",
    "    dataset,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9c03befc-8995-43f2-b180-80f44d573ab2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.3, inplace=False)\n",
       "    (3): Linear(in_features=1024, out_features=256, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.3, inplace=False)\n",
       "    (6): Linear(in_features=256, out_features=18, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda')\n",
    "model = torch.load('/opt/ml/code/model/Resnext50_32x4d-SKFold4-10-EarlyStopping-Accumulation.pt').to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c4b8a9f1-38e6-4dc3-8034-2a8b2808db15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12600/12600 [03:59<00:00, 52.56it/s]\n"
     ]
    }
   ],
   "source": [
    "# 모델이 테스트 데이터셋을 예측하고 결과를 저장합니다.\n",
    "all_predictions = []\n",
    "for images in tqdm(loader):\n",
    "    with torch.no_grad():\n",
    "        images = images.to(device)\n",
    "        pred = model(images)\n",
    "        pred = pred.argmax(dim=-1)\n",
    "        all_predictions.extend(pred.cpu().numpy())\n",
    "submission['ans'] = all_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b05da715-d35a-4700-8733-1e60f779a878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test inference is done!\n"
     ]
    }
   ],
   "source": [
    "# 제출할 파일을 저장합니다.\n",
    "submission.to_csv(os.path.join(test_dir, 'submission_ninth.csv'), index=False)\n",
    "print('test inference is done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c882adb-cf54-4cd3-8e9b-636417122028",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d18b97f3-a4d4-48a3-b9ba-b4b43b70b927",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import random\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import Resize, ToTensor, Normalize\n",
    "import torchsummary\n",
    "\n",
    "import Classification_Model as CM\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79fbcff6-f0d0-4e65-a442-730087ac2282",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = '/opt/ml/input/data/train'\n",
    "epochs = 100\n",
    "learning_rate= 1e-3\n",
    "batch_size = 64\n",
    "num_classes = 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea2b5887-4cb9-42dd-99ca-547d717b7900",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, img_paths, labels, transform):\n",
    "        self.img_paths = img_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.img_paths[idx])\n",
    "        label = self.labels[idx]\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, label\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e838efb-f55b-46af-b7ac-10f1a1cf2313",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(state, gender, age):\n",
    "    if state == 1:\n",
    "        if gender == \"male\":\n",
    "            if age < 30:\n",
    "                return 0\n",
    "            elif age < 60:\n",
    "                return 1\n",
    "            else:\n",
    "                return 2\n",
    "        else:\n",
    "            if age < 30:\n",
    "                return 3\n",
    "            elif age < 60:\n",
    "                return 4\n",
    "            else:\n",
    "                return 5\n",
    "    elif state == -1:\n",
    "        if gender == \"male\":\n",
    "            if age < 30:\n",
    "                return 6\n",
    "            elif age < 60:\n",
    "                return 7\n",
    "            else:\n",
    "                return 8\n",
    "        else:\n",
    "            if age < 30:\n",
    "                return 9\n",
    "            elif age < 60:\n",
    "                return 10\n",
    "            else:\n",
    "                return 11\n",
    "    else:\n",
    "        if gender == \"male\":\n",
    "            if age < 30:\n",
    "                return 12\n",
    "            elif age < 60:\n",
    "                return 13\n",
    "            else:\n",
    "                return 14\n",
    "        else:\n",
    "            if age < 30:\n",
    "                return 15\n",
    "            elif age < 60:\n",
    "                return 16\n",
    "            else:\n",
    "                return 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7dbd282-2fa5-4501-87ef-51a61cd76919",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df = pd.read_csv(train_dir + \"/train.csv\")\n",
    "# print(train_df.shape)\n",
    "paths = []\n",
    "labels = []\n",
    "list_persons = os.listdir(train_dir + \"/images\")\n",
    "for directory in list_persons:\n",
    "    if directory[0] != \".\":\n",
    "        path_person = train_dir + \"/images/\" + directory\n",
    "        list_file = os.listdir(path_person)\n",
    "        _, gender, _, age = directory.split(\"_\")\n",
    "        age = int(age)\n",
    "        for file in list_file:\n",
    "            if file[0] != \".\":\n",
    "                is_img = True\n",
    "                if file[0] == \"i\":\n",
    "                    state = -1\n",
    "                    idx = get_label(state, gender, age)\n",
    "                elif file[0] == \"n\":\n",
    "                    state = 0\n",
    "                    idx = get_label(state, gender, age)\n",
    "                elif file[0] == \"m\":\n",
    "                    state = 1\n",
    "                    idx = get_label(state, gender, age)\n",
    "                else:\n",
    "                    is_img = False\n",
    "                    pass\n",
    "                if is_img:\n",
    "                    paths.append(path_person + \"/\" + file)\n",
    "                    labels.append(idx)\n",
    "# print(len(paths))\n",
    "# print(len(labels))\n",
    "# for i in range(10):\n",
    "#     print(f\"path : {paths[i]} , label : {labels[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "395f5752-bea6-407f-8b12-49f366e0ee3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def over_sampling(x, y):\n",
    "    temp_x = np.array(x)\n",
    "    temp_y = np.array(y)\n",
    "    unique, counts = np.unique(temp_y, return_counts=True)\n",
    "    unique_cnt_dict = dict(zip(unique, counts))\n",
    "    max_cnt = max(unique_cnt_dict.values())\n",
    "    print(max_cnt)\n",
    "#     print(unique_cnt_dict)\n",
    "#     print(max_cnt)\n",
    "    for label in unique_cnt_dict:\n",
    "        label_cnt = unique_cnt_dict[label]\n",
    "        indexes = np.where(temp_y==label)\n",
    "#         print(indexes)\n",
    "        idx = np.random.choice(np.arange(len(indexes[0])), max_cnt-label_cnt, replace=True)\n",
    "#         print(type(indexes))\n",
    "#         print(type(idx))\n",
    "        extra_idx = indexes[0][idx]\n",
    "        extra_x = list(temp_x[extra_idx])\n",
    "        extra_y = list(temp_y[extra_idx])\n",
    "        x.extend(extra_x)\n",
    "        y.extend(extra_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3732d85d-388c-49fd-bc79-44c680438bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3268\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    Resize((512, 384), Image.BILINEAR),\n",
    "    ToTensor(),\n",
    "    Normalize(mean=(0.5, 0.5, 0.5), std=(0.2, 0.2, 0.2)),\n",
    "])\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(paths, labels, test_size=0.2, shuffle=True, stratify=labels, random_state=2021)\n",
    "over_sampling(x_train, y_train)\n",
    "train_dataset = TrainDataset(x_train, y_train, transform)\n",
    "valid_dataset = TrainDataset(x_valid, y_valid, transform)\n",
    "train_data_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "valid_data_loader = DataLoader(valid_dataset, batch_size=batch_size ,shuffle=False)\n",
    "train_data_loader_for_eval = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22b826ce-8a9e-4826-bdae-ac9f49d1821c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for X, Y in train_data_loader:\n",
    "#     print(f\"X : {X}, Y : {Y}\")\n",
    "# for i in range(10):\n",
    "#     print(train_dataset[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "178cc61d-076e-49ad-a34e-a1e89f8a0100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed\n",
    "SEED = 2021\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)  # type: ignore\n",
    "torch.backends.cudnn.deterministic = True  # type: ignore\n",
    "torch.backends.cudnn.benchmark = True  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb67359f-5aca-4af7-8038-c3499265656a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = torch.device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f71550a-75b6-40b7-b901-7fe12e7ab596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 256, 192]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 256, 192]             128\n",
      "              ReLU-3         [-1, 64, 256, 192]               0\n",
      "         MaxPool2d-4          [-1, 64, 128, 96]               0\n",
      "            Conv2d-5          [-1, 64, 128, 96]           4,096\n",
      "       BatchNorm2d-6          [-1, 64, 128, 96]             128\n",
      "              ReLU-7          [-1, 64, 128, 96]               0\n",
      "            Conv2d-8          [-1, 64, 128, 96]          36,864\n",
      "       BatchNorm2d-9          [-1, 64, 128, 96]             128\n",
      "             ReLU-10          [-1, 64, 128, 96]               0\n",
      "           Conv2d-11         [-1, 256, 128, 96]          16,384\n",
      "      BatchNorm2d-12         [-1, 256, 128, 96]             512\n",
      "           Conv2d-13         [-1, 256, 128, 96]          16,384\n",
      "      BatchNorm2d-14         [-1, 256, 128, 96]             512\n",
      "             ReLU-15         [-1, 256, 128, 96]               0\n",
      "       Bottleneck-16         [-1, 256, 128, 96]               0\n",
      "           Conv2d-17          [-1, 64, 128, 96]          16,384\n",
      "      BatchNorm2d-18          [-1, 64, 128, 96]             128\n",
      "             ReLU-19          [-1, 64, 128, 96]               0\n",
      "           Conv2d-20          [-1, 64, 128, 96]          36,864\n",
      "      BatchNorm2d-21          [-1, 64, 128, 96]             128\n",
      "             ReLU-22          [-1, 64, 128, 96]               0\n",
      "           Conv2d-23         [-1, 256, 128, 96]          16,384\n",
      "      BatchNorm2d-24         [-1, 256, 128, 96]             512\n",
      "             ReLU-25         [-1, 256, 128, 96]               0\n",
      "       Bottleneck-26         [-1, 256, 128, 96]               0\n",
      "           Conv2d-27          [-1, 64, 128, 96]          16,384\n",
      "      BatchNorm2d-28          [-1, 64, 128, 96]             128\n",
      "             ReLU-29          [-1, 64, 128, 96]               0\n",
      "           Conv2d-30          [-1, 64, 128, 96]          36,864\n",
      "      BatchNorm2d-31          [-1, 64, 128, 96]             128\n",
      "             ReLU-32          [-1, 64, 128, 96]               0\n",
      "           Conv2d-33         [-1, 256, 128, 96]          16,384\n",
      "      BatchNorm2d-34         [-1, 256, 128, 96]             512\n",
      "             ReLU-35         [-1, 256, 128, 96]               0\n",
      "       Bottleneck-36         [-1, 256, 128, 96]               0\n",
      "           Conv2d-37         [-1, 128, 128, 96]          32,768\n",
      "      BatchNorm2d-38         [-1, 128, 128, 96]             256\n",
      "             ReLU-39         [-1, 128, 128, 96]               0\n",
      "           Conv2d-40          [-1, 128, 64, 48]         147,456\n",
      "      BatchNorm2d-41          [-1, 128, 64, 48]             256\n",
      "             ReLU-42          [-1, 128, 64, 48]               0\n",
      "           Conv2d-43          [-1, 512, 64, 48]          65,536\n",
      "      BatchNorm2d-44          [-1, 512, 64, 48]           1,024\n",
      "           Conv2d-45          [-1, 512, 64, 48]         131,072\n",
      "      BatchNorm2d-46          [-1, 512, 64, 48]           1,024\n",
      "             ReLU-47          [-1, 512, 64, 48]               0\n",
      "       Bottleneck-48          [-1, 512, 64, 48]               0\n",
      "           Conv2d-49          [-1, 128, 64, 48]          65,536\n",
      "      BatchNorm2d-50          [-1, 128, 64, 48]             256\n",
      "             ReLU-51          [-1, 128, 64, 48]               0\n",
      "           Conv2d-52          [-1, 128, 64, 48]         147,456\n",
      "      BatchNorm2d-53          [-1, 128, 64, 48]             256\n",
      "             ReLU-54          [-1, 128, 64, 48]               0\n",
      "           Conv2d-55          [-1, 512, 64, 48]          65,536\n",
      "      BatchNorm2d-56          [-1, 512, 64, 48]           1,024\n",
      "             ReLU-57          [-1, 512, 64, 48]               0\n",
      "       Bottleneck-58          [-1, 512, 64, 48]               0\n",
      "           Conv2d-59          [-1, 128, 64, 48]          65,536\n",
      "      BatchNorm2d-60          [-1, 128, 64, 48]             256\n",
      "             ReLU-61          [-1, 128, 64, 48]               0\n",
      "           Conv2d-62          [-1, 128, 64, 48]         147,456\n",
      "      BatchNorm2d-63          [-1, 128, 64, 48]             256\n",
      "             ReLU-64          [-1, 128, 64, 48]               0\n",
      "           Conv2d-65          [-1, 512, 64, 48]          65,536\n",
      "      BatchNorm2d-66          [-1, 512, 64, 48]           1,024\n",
      "             ReLU-67          [-1, 512, 64, 48]               0\n",
      "       Bottleneck-68          [-1, 512, 64, 48]               0\n",
      "           Conv2d-69          [-1, 128, 64, 48]          65,536\n",
      "      BatchNorm2d-70          [-1, 128, 64, 48]             256\n",
      "             ReLU-71          [-1, 128, 64, 48]               0\n",
      "           Conv2d-72          [-1, 128, 64, 48]         147,456\n",
      "      BatchNorm2d-73          [-1, 128, 64, 48]             256\n",
      "             ReLU-74          [-1, 128, 64, 48]               0\n",
      "           Conv2d-75          [-1, 512, 64, 48]          65,536\n",
      "      BatchNorm2d-76          [-1, 512, 64, 48]           1,024\n",
      "             ReLU-77          [-1, 512, 64, 48]               0\n",
      "       Bottleneck-78          [-1, 512, 64, 48]               0\n",
      "           Conv2d-79          [-1, 256, 64, 48]         131,072\n",
      "      BatchNorm2d-80          [-1, 256, 64, 48]             512\n",
      "             ReLU-81          [-1, 256, 64, 48]               0\n",
      "           Conv2d-82          [-1, 256, 32, 24]         589,824\n",
      "      BatchNorm2d-83          [-1, 256, 32, 24]             512\n",
      "             ReLU-84          [-1, 256, 32, 24]               0\n",
      "           Conv2d-85         [-1, 1024, 32, 24]         262,144\n",
      "      BatchNorm2d-86         [-1, 1024, 32, 24]           2,048\n",
      "           Conv2d-87         [-1, 1024, 32, 24]         524,288\n",
      "      BatchNorm2d-88         [-1, 1024, 32, 24]           2,048\n",
      "             ReLU-89         [-1, 1024, 32, 24]               0\n",
      "       Bottleneck-90         [-1, 1024, 32, 24]               0\n",
      "           Conv2d-91          [-1, 256, 32, 24]         262,144\n",
      "      BatchNorm2d-92          [-1, 256, 32, 24]             512\n",
      "             ReLU-93          [-1, 256, 32, 24]               0\n",
      "           Conv2d-94          [-1, 256, 32, 24]         589,824\n",
      "      BatchNorm2d-95          [-1, 256, 32, 24]             512\n",
      "             ReLU-96          [-1, 256, 32, 24]               0\n",
      "           Conv2d-97         [-1, 1024, 32, 24]         262,144\n",
      "      BatchNorm2d-98         [-1, 1024, 32, 24]           2,048\n",
      "             ReLU-99         [-1, 1024, 32, 24]               0\n",
      "      Bottleneck-100         [-1, 1024, 32, 24]               0\n",
      "          Conv2d-101          [-1, 256, 32, 24]         262,144\n",
      "     BatchNorm2d-102          [-1, 256, 32, 24]             512\n",
      "            ReLU-103          [-1, 256, 32, 24]               0\n",
      "          Conv2d-104          [-1, 256, 32, 24]         589,824\n",
      "     BatchNorm2d-105          [-1, 256, 32, 24]             512\n",
      "            ReLU-106          [-1, 256, 32, 24]               0\n",
      "          Conv2d-107         [-1, 1024, 32, 24]         262,144\n",
      "     BatchNorm2d-108         [-1, 1024, 32, 24]           2,048\n",
      "            ReLU-109         [-1, 1024, 32, 24]               0\n",
      "      Bottleneck-110         [-1, 1024, 32, 24]               0\n",
      "          Conv2d-111          [-1, 256, 32, 24]         262,144\n",
      "     BatchNorm2d-112          [-1, 256, 32, 24]             512\n",
      "            ReLU-113          [-1, 256, 32, 24]               0\n",
      "          Conv2d-114          [-1, 256, 32, 24]         589,824\n",
      "     BatchNorm2d-115          [-1, 256, 32, 24]             512\n",
      "            ReLU-116          [-1, 256, 32, 24]               0\n",
      "          Conv2d-117         [-1, 1024, 32, 24]         262,144\n",
      "     BatchNorm2d-118         [-1, 1024, 32, 24]           2,048\n",
      "            ReLU-119         [-1, 1024, 32, 24]               0\n",
      "      Bottleneck-120         [-1, 1024, 32, 24]               0\n",
      "          Conv2d-121          [-1, 256, 32, 24]         262,144\n",
      "     BatchNorm2d-122          [-1, 256, 32, 24]             512\n",
      "            ReLU-123          [-1, 256, 32, 24]               0\n",
      "          Conv2d-124          [-1, 256, 32, 24]         589,824\n",
      "     BatchNorm2d-125          [-1, 256, 32, 24]             512\n",
      "            ReLU-126          [-1, 256, 32, 24]               0\n",
      "          Conv2d-127         [-1, 1024, 32, 24]         262,144\n",
      "     BatchNorm2d-128         [-1, 1024, 32, 24]           2,048\n",
      "            ReLU-129         [-1, 1024, 32, 24]               0\n",
      "      Bottleneck-130         [-1, 1024, 32, 24]               0\n",
      "          Conv2d-131          [-1, 256, 32, 24]         262,144\n",
      "     BatchNorm2d-132          [-1, 256, 32, 24]             512\n",
      "            ReLU-133          [-1, 256, 32, 24]               0\n",
      "          Conv2d-134          [-1, 256, 32, 24]         589,824\n",
      "     BatchNorm2d-135          [-1, 256, 32, 24]             512\n",
      "            ReLU-136          [-1, 256, 32, 24]               0\n",
      "          Conv2d-137         [-1, 1024, 32, 24]         262,144\n",
      "     BatchNorm2d-138         [-1, 1024, 32, 24]           2,048\n",
      "            ReLU-139         [-1, 1024, 32, 24]               0\n",
      "      Bottleneck-140         [-1, 1024, 32, 24]               0\n",
      "          Conv2d-141          [-1, 512, 32, 24]         524,288\n",
      "     BatchNorm2d-142          [-1, 512, 32, 24]           1,024\n",
      "            ReLU-143          [-1, 512, 32, 24]               0\n",
      "          Conv2d-144          [-1, 512, 16, 12]       2,359,296\n",
      "     BatchNorm2d-145          [-1, 512, 16, 12]           1,024\n",
      "            ReLU-146          [-1, 512, 16, 12]               0\n",
      "          Conv2d-147         [-1, 2048, 16, 12]       1,048,576\n",
      "     BatchNorm2d-148         [-1, 2048, 16, 12]           4,096\n",
      "          Conv2d-149         [-1, 2048, 16, 12]       2,097,152\n",
      "     BatchNorm2d-150         [-1, 2048, 16, 12]           4,096\n",
      "            ReLU-151         [-1, 2048, 16, 12]               0\n",
      "      Bottleneck-152         [-1, 2048, 16, 12]               0\n",
      "          Conv2d-153          [-1, 512, 16, 12]       1,048,576\n",
      "     BatchNorm2d-154          [-1, 512, 16, 12]           1,024\n",
      "            ReLU-155          [-1, 512, 16, 12]               0\n",
      "          Conv2d-156          [-1, 512, 16, 12]       2,359,296\n",
      "     BatchNorm2d-157          [-1, 512, 16, 12]           1,024\n",
      "            ReLU-158          [-1, 512, 16, 12]               0\n",
      "          Conv2d-159         [-1, 2048, 16, 12]       1,048,576\n",
      "     BatchNorm2d-160         [-1, 2048, 16, 12]           4,096\n",
      "            ReLU-161         [-1, 2048, 16, 12]               0\n",
      "      Bottleneck-162         [-1, 2048, 16, 12]               0\n",
      "          Conv2d-163          [-1, 512, 16, 12]       1,048,576\n",
      "     BatchNorm2d-164          [-1, 512, 16, 12]           1,024\n",
      "            ReLU-165          [-1, 512, 16, 12]               0\n",
      "          Conv2d-166          [-1, 512, 16, 12]       2,359,296\n",
      "     BatchNorm2d-167          [-1, 512, 16, 12]           1,024\n",
      "            ReLU-168          [-1, 512, 16, 12]               0\n",
      "          Conv2d-169         [-1, 2048, 16, 12]       1,048,576\n",
      "     BatchNorm2d-170         [-1, 2048, 16, 12]           4,096\n",
      "            ReLU-171         [-1, 2048, 16, 12]               0\n",
      "      Bottleneck-172         [-1, 2048, 16, 12]               0\n",
      "AdaptiveAvgPool2d-173           [-1, 2048, 1, 1]               0\n",
      "          Linear-174                 [-1, 1000]       2,049,000\n",
      "          ResNet-175                 [-1, 1000]               0\n",
      "          Linear-176                  [-1, 500]         500,500\n",
      "            ReLU-177                  [-1, 500]               0\n",
      "          Linear-178                   [-1, 18]           9,018\n",
      "================================================================\n",
      "Total params: 26,066,550\n",
      "Trainable params: 26,066,550\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 2.25\n",
      "Forward/backward pass size (MB): 1122.79\n",
      "Params size (MB): 99.44\n",
      "Estimated Total Size (MB): 1224.47\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = CM.Model(num_classes=num_classes)\n",
    "torchsummary.summary(model, (3, 512, 384), device=\"cpu\")\n",
    "model = model.to(device)\n",
    "# for param in model.parameters():\n",
    "#     param.requires_grad = False\n",
    "# for param in model.linear_layer1.parameters():\n",
    "#     param.requires_grad = True\n",
    "# for param in model.linear_layer2.parameters():\n",
    "#     param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2469074c-9ea1-4c6e-a74d-5e6c6c356881",
   "metadata": {},
   "outputs": [],
   "source": [
    "# weight = torch.tensor([1.491, 1.993, 9.843, 1.116, 1.0, 7.495, 7.454, 9.963, 49.217, 5.581, 5.0, 37.477, 7.454, 9.963, 49.217, 5.581, 5.0, 37.477])\n",
    "# criterion = nn.CrossEntropyLoss(weight=weight).to(device)\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76a4cab1-7a26-4787-8491-5a8c67762475",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, data):\n",
    "    matrix = np.zeros((num_classes, num_classes))\n",
    "    correct_cnt = 0\n",
    "    total_cnt = 0\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for X, Y in tqdm(data):\n",
    "            X = X.to(device)\n",
    "            Y = Y.to(device)\n",
    "            pred = torch.argmax(model(X), dim=1)\n",
    "            model_pred = pred.squeeze()\n",
    "            ground_truth = Y.squeeze()\n",
    "            for i in range(X.size(0)):\n",
    "                matrix[model_pred[i].item(), ground_truth[i].item()] += 1\n",
    "            correct_cnt += sum(pred == Y).item()\n",
    "            total_cnt += X.size(0)\n",
    "    recall = np.array([matrix[i, i] for i in range(num_classes)])\n",
    "    precision = np.array([matrix[i, i] for i in range(num_classes)])\n",
    "    recall = recall/matrix.sum(axis=1)\n",
    "    precision = precision/matrix.sum(axis=0)\n",
    "    np.nan_to_num(recall, copy=False, nan=0.0)\n",
    "    np.nan_to_num(precision, copy=False, nan=0.0)\n",
    "#     print(\"matrix : \", matrix)\n",
    "#     print(\"recall : \", recall)\n",
    "#     print(\"precision : \", precision)\n",
    "    sum_recall = 0\n",
    "    cnt_recall = 0\n",
    "    sum_precision = 0\n",
    "    cnt_precision = 0\n",
    "    for i in range(num_classes):\n",
    "        if recall[i] != 0.0:\n",
    "            sum_recall += recall[i]\n",
    "            cnt_recall += 1\n",
    "        if precision[i] != 0.0:\n",
    "            sum_precision += precision[i]\n",
    "            cnt_precision += 1\n",
    "    recall_score = sum_recall / cnt_recall\n",
    "    precision_score = sum_precision / cnt_precision\n",
    "#     print(\"recall_score : \", recall_score)\n",
    "#     print(\"precision_score : \", precision_score)\n",
    "    f1_score = (2*precision_score*recall_score)/(precision_score+recall_score)\n",
    "#     print(\"f1_score : \", f1_score)\n",
    "    model.train()\n",
    "    return correct_cnt/total_cnt, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "43af3ba9-c1cf-43f4-8840-301e1592e31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a64a38f1-806a-4bb4-94b0-a9fe2d3d301b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 919/919 [16:39<00:00,  1.09s/it]\n",
      "100%|██████████| 60/60 [00:33<00:00,  1.77it/s]\n",
      "100%|██████████| 920/920 [08:34<00:00,  1.79it/s]\n",
      "  0%|          | 0/919 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1, average_cost : 0.3676, Train_Acc : 0.781, Train_f1_score : 0.791, Val_Acc : 0.667, Val_f1_score : 0.6331019102163067\n",
      "Model Saved!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 919/919 [15:57<00:00,  1.04s/it]\n",
      "100%|██████████| 60/60 [00:30<00:00,  1.98it/s]\n",
      "100%|██████████| 920/920 [07:53<00:00,  1.94it/s]\n",
      "  0%|          | 0/919 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 2, average_cost : 0.1456, Train_Acc : 0.961, Train_f1_score : 0.962, Val_Acc : 0.931, Val_f1_score : 0.8923373767107091\n",
      "Model Saved!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 919/919 [15:57<00:00,  1.04s/it]\n",
      "100%|██████████| 60/60 [00:30<00:00,  1.95it/s]\n",
      "100%|██████████| 920/920 [07:59<00:00,  1.92it/s]\n",
      "  0%|          | 0/919 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 3, average_cost : 0.0993, Train_Acc : 0.987, Train_f1_score : 0.987, Val_Acc : 0.951, Val_f1_score : 0.9257701750927829\n",
      "Model Saved!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 919/919 [15:54<00:00,  1.04s/it]\n",
      "100%|██████████| 60/60 [00:30<00:00,  1.94it/s]\n",
      "100%|██████████| 920/920 [08:00<00:00,  1.92it/s]\n",
      "  0%|          | 0/919 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 4, average_cost : 0.0720, Train_Acc : 0.984, Train_f1_score : 0.984, Val_Acc : 0.947, Val_f1_score : 0.927044436268569\n",
      "Model Saved!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 100/919 [01:44<14:16,  1.05s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-f7f915aeba5c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mcost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhypothesis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mcost\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;31m#         print(f\"Batch {idx} Complete\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mavg_cost\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcost\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtotal_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0mbeta1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'betas'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m             F.adam(params_with_grad,\n\u001b[0m\u001b[1;32m    109\u001b[0m                    \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m                    \u001b[0mexp_avgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/optim/functional.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_exp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m             \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "total_batch = len(train_data_loader)\n",
    "# print(\"mini_batch per epoch : \", total_batch)\n",
    "model.train()\n",
    "previous_val_f1 = 0\n",
    "previous_val_acc = 0\n",
    "patient = 2\n",
    "model_save_path = \"./trained_model\"\n",
    "cnt = 0\n",
    "is_early_stop = False\n",
    "for epoch in range(epochs):\n",
    "    avg_cost = 0\n",
    "    for idx, (X, Y) in enumerate(tqdm(train_data_loader)):\n",
    "#         print(X.shape)\n",
    "        X = X.to(device)\n",
    "        Y = Y.to(device)\n",
    "#         print(Y)\n",
    "#         Y = torch.zeros(batch_size, 18).to(device)\n",
    "#         Y[range(batch_size), label] = 1\n",
    "        hypothesis = model(X)\n",
    "        optimizer.zero_grad()\n",
    "        cost = criterion(hypothesis, Y)\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "#         print(f\"Batch {idx} Complete\")\n",
    "        avg_cost += cost/total_batch\n",
    "    \n",
    "    val_acc, val_f1 = eval_model(model, valid_data_loader)\n",
    "    train_acc, train_f1 = eval_model(model, train_data_loader_for_eval)\n",
    "    \n",
    "    if val_f1 > previous_val_f1:\n",
    "        torch.save(model.state_dict(), os.path.join(model_save_path, \"model.pt\"))\n",
    "        previous_val_f1 = val_f1\n",
    "        previous_val_acc = val_acc\n",
    "        print(f\"epoch : {epoch+1}, average_cost : {avg_cost:.4f}, Train_Acc : {train_acc:.3f}, Train_f1_score : {train_f1:.3f}, Val_Acc : {val_acc:.3f}, Val_f1_score : {val_f1}\")\n",
    "        print(\"Model Saved!!\")\n",
    "        cnt = 0\n",
    "    else:\n",
    "        cnt += 1\n",
    "        if cnt >= patient:\n",
    "            print(f\"epoch : {epoch+1}, average_cost : {avg_cost:.4f}, Train_Acc : {train_acc:.3f}, Train_f1_score : {train_f1:.3f}, Val_Acc : {val_acc:.3f}, Val_f1_score : {val_f1}\")\n",
    "            print(f\"Val_f1_score does not get better. prev : {previous_val_f1} -> cur : {val_f1}\")\n",
    "            print(\"Early stop\")\n",
    "            is_early_stop = True\n",
    "            break\n",
    "        else:\n",
    "            print(f\"epoch : {epoch+1}, average_cost : {avg_cost:.4f}, Train_Acc : {train_acc:.3f}, Train_f1_score : {train_f1:.3f}, Val_Acc : {val_acc:.3f}, Val_f1_score : {val_f1}\")\n",
    "            print(f\"Val_f1_score does not get better. prev : {previous_val_f1} -> cur : {val_f1}\")\n",
    "    if is_early_stop:\n",
    "        break\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Aug 25 14:02:41 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.80.02    Driver Version: 450.80.02    CUDA Version: 11.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-PCIE...  Off  | 00000000:00:05.0 Off |                  Off |\n",
      "| N/A   38C    P0    35W / 250W |      0MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import tqdm\n",
    "import glob\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchsummary import summary\n",
    "from torchvision import models\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import Resize, ToTensor, Normalize\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 변수설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = '/opt/ml/input/data/train'\n",
    "train_images_dir = train_dir + '/images/'\n",
    "train_label = train_dir + '/train.csv'\n",
    "test_dir = '/opt/ml/input/data/eval'\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TrainDataList 만들기 <- 미완성 DataSet class에서 마스크 유무에 따른 라벨을 추가해줘야함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mask2.jpg', 'mask4.jpg', 'mask5.jpg', 'mask3.jpg', 'incorrect_mask.jpg', 'mask1.jpg', 'normal.jpg'] [1, 1, 1, 1, 0, 1, 2]\n"
     ]
    }
   ],
   "source": [
    "pd_train = pd.read_csv(train_label)\n",
    "train_path_list = [ train_images_dir+'/'+x +'/' for x in pd_train['path']]\n",
    "def create_train_data_list(path_list):\n",
    "    count = 0\n",
    "    train_data_list = []\n",
    "    train_label_list = []\n",
    "    train_mask_label_list = []\n",
    "    for data_path in path_list:\n",
    "        train_data_list.append(glob.glob(data_path+'*'))\n",
    "        temp_mask_label = [mask_data for mask_data in os.listdir(data_path) if not '_' in mask_data or ('incorrect' in mask_data and not '_incorrect' in mask_data )]\n",
    "        train_mask_label_list = [0 if 'incorrect_mask' in mask_data else 1 if 'mask' in mask_data else 2 for mask_data in temp_mask_label]\n",
    "#         print(temp_mask_label[0], train_mask_label_list[0])\n",
    "        temp_train_label = data_path.split('_')\n",
    "        train_label_list.append([temp_train_label[1],temp_train_label[3].rstrip('/')])\n",
    "    print(temp_mask_label[0:7], train_mask_label_list[0:7])\n",
    "    return [train_data_list, train_mask_label_list, train_label_list] #copy.deepcopy(train_data_list)\n",
    "\n",
    "temp_train_info = create_train_data_list(train_path_list)\n",
    "# print(train_info[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label 만들어 주기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|class|mask|gender|age|\n",
    "|:-:|:-:|:-:|:-:|\n",
    "|0|1|0|0|\n",
    "|1|1|0|1|\n",
    "|2|1|0|2|\n",
    "|3|1|1|0|\n",
    "|4|1|1|1|\n",
    "|5|1|1|2|\n",
    "|6|0|0|0|\n",
    "|7|0|0|1|\n",
    "|8|0|0|2|\n",
    "|9|0|1|0|\n",
    "|10|0|1|1|\n",
    "|11|0|1|2|\n",
    "|12|2|0|0|\n",
    "|13|2|0|1|\n",
    "|14|2|0|2|\n",
    "|15|2|1|0|\n",
    "|16|2|1|1|\n",
    "|17|2|1|2|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_mask(data):\n",
    "    result = 1 if data == 1 else 0 if data == 0 else 2\n",
    "    return result\n",
    "\n",
    "def check_gender(gender):\n",
    "    result = 1 if 'female' in gender else 0\n",
    "    return result\n",
    "\n",
    "def check_age(age):\n",
    "    result_number = 0 if age < 30 else 2 if age >= 60 else 1\n",
    "    return result_number\n",
    "\n",
    "def label_classification(data, gender, age):\n",
    "    result = 0\n",
    "    # mask : wear\n",
    "    if data == 1 and gender == 0 and age == 0:\n",
    "        result = 0\n",
    "    elif data == 1 and gender == 0 and age == 1:\n",
    "        result = 1\n",
    "    elif data == 1 and gender == 0 and age == 2:\n",
    "        result = 2\n",
    "    elif data == 1 and gender == 1 and age == 0:\n",
    "        result = 3\n",
    "    elif data == 1 and gender == 1 and age == 1:\n",
    "        result = 4\n",
    "    elif data == 1 and gender == 1 and age == 2:\n",
    "        result = 5\n",
    "    # mask : incorrect\n",
    "    elif data == 0 and gender == 0 and age == 0:\n",
    "        result = 6\n",
    "    elif data == 0 and gender == 0 and age == 1:\n",
    "        result = 7\n",
    "    elif data == 0 and gender == 0 and age == 2:\n",
    "        result = 8\n",
    "    if data == 0 and gender == 1 and age == 0:\n",
    "        result = 9\n",
    "    elif data == 0 and gender == 1 and age == 1:\n",
    "        result = 10\n",
    "    elif data == 0 and gender == 1 and age == 2:\n",
    "        result = 11\n",
    "    # mask : not wear\n",
    "    elif data == 2 and gender == 0 and age == 0:\n",
    "        result = 12\n",
    "    elif data == 2 and gender == 0 and age == 1:\n",
    "        result = 13\n",
    "    elif data == 2 and gender == 0 and age == 2:\n",
    "        result = 14\n",
    "    elif data == 2 and gender == 1 and age == 0:\n",
    "        result = 15\n",
    "    elif data == 2 and gender == 1 and age == 1:\n",
    "        result = 16\n",
    "    elif data == 2 and gender == 1 and age == 2:\n",
    "        result = 17\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "data_path, mask_list, label_list = temp_train_info\n",
    "# print(mask[0:7],label[0])\n",
    "index = 0\n",
    "new_label = []\n",
    "count = 0\n",
    "for label in label_list:\n",
    "    gender, age = label\n",
    "    gender_state = check_gender(gender)\n",
    "    age_state = check_age(int(age))\n",
    "    index *= count\n",
    "    count += 1\n",
    "    mask = mask_list[index:index+7]\n",
    "    for target_mask in mask:\n",
    "        mask_state = check_mask(target_mask)\n",
    "        result_class = label_classification(mask_state, gender_state, age_state)\n",
    "        # print(mask_state,gender_state,age_state,result_class)\n",
    "        new_label.append(result_class)\n",
    "\n",
    "new_data_path = [target_path for in_target_path in data_path for target_path in in_target_path ]\n",
    "col_name = ['data_path', 'label']\n",
    "new_info = []\n",
    "series_data_path = pd.Series(new_data_path, name=col_name[0])\n",
    "series_new_label = pd.Series(new_label, name=col_name[1])\n",
    "df_new_info = pd.concat([series_data_path, series_new_label],axis=1)\n",
    "df_new_info.to_csv('/opt/ml/new_label.csv',mode='w')\n",
    "\n",
    "# series_new_label.head(14)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self, num_classes: int = 1000):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(32, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "#         print(1)\n",
    "        x = self.features(x)\n",
    "#         print(2)\n",
    "        x = self.avgpool(x)\n",
    "#         print(3)\n",
    "        x = torch.flatten(x, 1)\n",
    "#         print(4)\n",
    "        x = self.classifier(x)\n",
    "#         print(5)\n",
    "        return x\n",
    "\n",
    "    def init_param(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m,nn.Conv2d): # init conv\n",
    "                nn.init.kaiming_normal_(m.weight)\n",
    "                nn.init.zeros_(m.bias)\n",
    "            elif isinstance(m,nn.BatchNorm2d): # init BN\n",
    "                nn.init.constant_(m.weight,1)\n",
    "                nn.init.constant_(m.bias,0)\n",
    "            elif isinstance(m,nn.Linear): # lnit dense\n",
    "                nn.init.kaiming_normal_(m.weight)\n",
    "                nn.init.zeros_(m.bias)\n",
    "\n",
    "cnn_model = MyModel(num_classes=18).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "class ConvolutionalNeuralNetworkClass(nn.Module):\n",
    "    \"\"\"\n",
    "        Convolutional Neural Network (CNN) Class\n",
    "    \"\"\"\n",
    "    def __init__(self,name='cnn',xdim=[1,28,28],\n",
    "                 ksize=3,cdims=[32,64],hdims=[1024,128],ydim=10,\n",
    "                 USE_BATCHNORM=False):\n",
    "        super(ConvolutionalNeuralNetworkClass,self).__init__()\n",
    "        self.name = name\n",
    "        self.xdim = xdim\n",
    "        self.ksize = ksize\n",
    "        self.cdims = cdims\n",
    "        self.hdims = hdims\n",
    "        self.ydim = ydim\n",
    "        self.USE_BATCHNORM = USE_BATCHNORM\n",
    "\n",
    "        # Convolutional layers\n",
    "        self.layers = []\n",
    "        prev_cdim = self.xdim[0]\n",
    "        for cdim in self.cdims: # for each hidden layer\n",
    "            self.layers.append(\n",
    "                nn.Conv2d(\n",
    "                    # FILL IN HERE\n",
    "                    in_channels = prev_cdim,\n",
    "                    out_channels = cdim,\n",
    "                    kernel_size = self.ksize,\n",
    "                    stride=(1,1),\n",
    "                    padding=self.ksize//2\n",
    "                )) # convlution \n",
    "            if self.USE_BATCHNORM:\n",
    "                self.layers.append(nn.BatchNorm2d(cdim)) # batch-norm\n",
    "            self.layers.append(nn.ReLU(True))  # activation\n",
    "            self.layers.append(nn.MaxPool2d(kernel_size=(2,2), stride=(2,2))) # max-pooling \n",
    "            self.layers.append(nn.Dropout2d(p=0.5))  # dropout\n",
    "            self.layers.append(nn.Softmax2d())\n",
    "            prev_cdim = cdim\n",
    "\n",
    "        # Dense layers\n",
    "        self.layers.append(nn.Flatten())\n",
    "        prev_hdim = prev_cdim*(self.xdim[1]//(2**len(self.cdims)))*(self.xdim[2]//(2**len(self.cdims)))\n",
    "        for hdim in self.hdims:\n",
    "            self.layers.append(nn.Linear(\n",
    "                # FILL IN HERE\n",
    "                prev_hdim, hdim, bias=True\n",
    "                               ))\n",
    "            self.layers.append(nn.ReLU(True))  # activation\n",
    "            prev_hdim = hdim\n",
    "        # Final layer (without activation)\n",
    "        self.layers.append(nn.Linear(prev_hdim,self.ydim,bias=True))\n",
    "\n",
    "        # Concatenate all layers \n",
    "        self.net = nn.Sequential()\n",
    "        for l_idx,layer in enumerate(self.layers):\n",
    "            layer_name = \"%s_%02d\"%(type(layer).__name__.lower(),l_idx)\n",
    "            self.net.add_module(layer_name,layer)\n",
    "        self.init_param() # initialize parameters\n",
    "        \n",
    "    def init_param(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m,nn.Conv2d): # init conv\n",
    "                nn.init.kaiming_normal_(m.weight)\n",
    "                nn.init.zeros_(m.bias)\n",
    "            elif isinstance(m,nn.BatchNorm2d): # init BN\n",
    "                nn.init.constant_(m.weight,1)\n",
    "                nn.init.constant_(m.bias,0)\n",
    "            elif isinstance(m,nn.Linear): # lnit dense\n",
    "                nn.init.kaiming_normal_(m.weight)\n",
    "                nn.init.zeros_(m.bias)\n",
    "            \n",
    "    def forward(self,x):\n",
    "        return self.net(x)\n",
    "\n",
    "C = ConvolutionalNeuralNetworkClass(\n",
    "    name='cnn',xdim=[3,384,384],ksize=3,cdims=[64],\n",
    "    hdims=[64],ydim=18).to(device)\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optm = optim.Adam(C.parameters(),lr=1e-3)\n",
    "C.init_param() # initialize parameters\n",
    "C.train() # to train mode \n",
    "print (\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretrained Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DenseNet161"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyPreTrainedModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyPreTrainedModel, self).__init__()\n",
    "        self.dense161 = models.densenet161(pretrained=True)\n",
    "        self.linear1 = nn.Linear(1000, 18)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dense161(x)\n",
    "        return self.linear1(x)\n",
    "\n",
    "pretrained_model = MyPreTrainedModel().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## inception_V3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyPreTrainedModel1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyPreTrainedModel1, self).__init__()\n",
    "        self.inception3 = models.inception_v3(pretrained=True)\n",
    "        self.linear1 = nn.Linear(1000, 18)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.inception3(x)\n",
    "        return self.linear1(x)\n",
    "\n",
    "pretrained_model = MyPreTrainedModel1().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyPreTrainedModel2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyPreTrainedModel2, self).__init__()\n",
    "        self.vgg19 = models.vgg19(pretrained=True)\n",
    "        self.linear1 = nn.Linear(1000, 18)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.vgg19(x)\n",
    "        return self.linear1(x)\n",
    "\n",
    "pretrained_model = MyPreTrainedModel2().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PreTrained Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pretrained_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-644814e209e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# print(pretrained_model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m384\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'pretrained_model' is not defined"
     ]
    }
   ],
   "source": [
    "# print(pretrained_model)\n",
    "summary(pretrained_model, input_size=(3,512,384))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataSet 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_info = pd.read_csv('/opt/ml/new_label.csv')\n",
    "# data_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskDataSet(Dataset):\n",
    "    def __init__(self, data_info, transform, train=True):\n",
    "        self.row = 512\n",
    "        self.column = 384\n",
    "        self.x = data_info['data_path']\n",
    "        self.y = data_info['label']\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        len_dataset = len(self.x)\n",
    "        return len_dataset\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.x[idx])\n",
    "        x = self.transform(image)\n",
    "        y = self.y[idx]\n",
    "\n",
    "        return torch.tensor(x, dtype=torch.float), torch.tensor(y, dtype=int)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "18900"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_iter = MaskDataSet(data_info = data_info, transform=transforms.Compose([transforms.Compose([\n",
    "    Resize((512, 384), Image.BILINEAR),\n",
    "    # transforms.CenterCrop(384),\n",
    "    ToTensor(),\n",
    "    Normalize(mean=(0.5, 0.5, 0.5), std=(0.2, 0.2, 0.2)),\n",
    "])]),train=True)\n",
    "len(train_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# collate 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_collate_fn(samples):\n",
    "    collate_X = []\n",
    "    collate_y = []\n",
    "    ######################################TODO######################################\n",
    "    collate_x = [sample['data_path'] for sample in samples]\n",
    "    collate_y = [sample['label'] for sample in samples]\n",
    "    ################################################################################\n",
    "    return {'X': torch.stack(collate_X),\n",
    "             'y': torch.stack(collate_y)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataLoader 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "train_loader = torch.utils.data.DataLoader(train_iter,batch_size=BATCH_SIZE,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image, label = next(iter(train_loader))\n",
    "# image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss, Optimizer, epoch 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "# optm = optim.Adam(cnn_model.parameters(),lr=1e-3)\n",
    "optm = optim.Adam(pretrained_model.parameters(),lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCH = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Aug 25 13:58:57 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.80.02    Driver Version: 450.80.02    CUDA Version: 11.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-PCIE...  Off  | 00000000:00:05.0 Off |                  Off |\n",
      "| N/A   38C    P0    37W / 250W |   3161MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 Train 및 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2363 [00:00<?, ?it/s]<ipython-input-6-d0d86192c460>:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(x, dtype=torch.float), torch.tensor(y, dtype=int)\n",
      "  0%|          | 0/2363 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'InceptionOutputs' object has no attribute 'dim'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-2b0c85e9998e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m# 순전파 + 역전파 + 최적화를 한 후\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpretrained_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-4ec57c767744>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minception3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mpretrained_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMyPreTrainedModel1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1686\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mTensor\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtens_ops\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhas_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtens_ops\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1687\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtens_ops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1688\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1689\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1690\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'InceptionOutputs' object has no attribute 'dim'"
     ]
    }
   ],
   "source": [
    "# torch.cuda.empty_cache()\n",
    "# cnn_model.train()\n",
    "# C.train()\n",
    "pretrained_model.train()\n",
    "# target = pretrained_model\n",
    "for epoch in range(NUM_EPOCH):   # 데이터셋을 수차례 반복합니다.\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in tqdm.tqdm(train_loader):\n",
    "        # [inputs, labels]의 목록인 data로부터 입력을 받은 후;\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        # 변화도(Gradient) 매개변수를 0으로 만들고\n",
    "        optm.zero_grad()\n",
    "\n",
    "        # 순전파 + 역전파 + 최적화를 한 후\n",
    "        logits = pretrained_model(inputs)\n",
    "\n",
    "        _, preds = torch.max(logits, 1)\n",
    "        loss = criterion(logits, labels)\n",
    "        loss.backward() \n",
    "        optm.step() \n",
    " \n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "FOLD 0\n",
      "--------------------------------\n",
      "Starting epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-d0d86192c460>:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(x, dtype=torch.float), torch.tensor(y, dtype=int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Training process has finished. Saving trained model.\n",
      "Starting testing\n"
     ]
    }
   ],
   "source": [
    "k_folds = 5\n",
    "num_epochs = 3\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "model_name = 'VGG'\n",
    "  \n",
    "# For fold results\n",
    "results = {}\n",
    "  \n",
    "# Set fixed random number seed\n",
    "torch.manual_seed(42)\n",
    "  \n",
    "# Define the K-fold Cross Validator\n",
    "kfold = KFold(n_splits=k_folds, shuffle=True)\n",
    "    \n",
    "# Start print\n",
    "print('--------------------------------')\n",
    "\n",
    "# K-fold Cross Validation model evaluation\n",
    "for fold, (train_ids, test_ids) in enumerate(kfold.split(train_iter)):\n",
    "    \n",
    "    # Print\n",
    "    print(f'FOLD {fold}')\n",
    "    print('--------------------------------')\n",
    "        \n",
    "    # Sample elements randomly from a given list of ids, no replacement.\n",
    "    test_loader = torch.utils.data.DataLoader(train_iter,batch_size=BATCH_SIZE,shuffle=True)\n",
    "\n",
    "        \n",
    "    # Run the training loop for defined number of epochs\n",
    "    for epoch in range(0, num_epochs):\n",
    "\n",
    "        # Print epoch\n",
    "        print(f'Starting epoch {epoch+1}')\n",
    "\n",
    "        # Set current loss value\n",
    "        current_loss = 0.0\n",
    "\n",
    "        # Iterate over the DataLoader for training data\n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            \n",
    "            # Get inputs\n",
    "            inputs, targets = data\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            # Zero the gradients\n",
    "            optm.zero_grad()\n",
    "\n",
    "            # Perform forward pass\n",
    "            outputs = pretrained_model(inputs)\n",
    "\n",
    "            # Compute loss\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            # Perform backward pass\n",
    "            loss.backward()\n",
    "\n",
    "            # Perform optimization\n",
    "            optm.step()\n",
    "\n",
    "            # Print statistics\n",
    "            current_loss += loss.item()\n",
    "            if i % 500 == 499:\n",
    "                print('Loss after mini-batch %5d: %.3f' %(i + 1, current_loss / 500))\n",
    "                current_loss = 0.0\n",
    "                \n",
    "    # Process is complete.\n",
    "    print('Training process has finished. Saving trained model.')\n",
    "\n",
    "    # Print about testing\n",
    "    print('Starting testing')\n",
    "        \n",
    "    # Saving the model\n",
    "    save_path = f'./{model_name}-fold-{fold}.pth'\n",
    "    torch.save(pretrained_model.state_dict(), save_path)\n",
    "    if k_folds == 5:\n",
    "        break\n",
    "\n",
    "    # Evaluationfor this fold\n",
    "#     correct, total = 0, 0\n",
    "#     with torch.no_grad():\n",
    "\n",
    "#         # Iterate over the test data and generate predictions\n",
    "#         for i, data in enumerate(test_loader, 0):\n",
    "\n",
    "#         # Get inputs\n",
    "#         inputs, targets = data\n",
    "\n",
    "#         # Generate outputs\n",
    "#         outputs = pretrained_model(inputs)\n",
    "\n",
    "#         # Set total and correct\n",
    "#         _, predicted = torch.max(outputs.data, 1)\n",
    "#         total += targets.size(0)\n",
    "#         correct += (predicted == targets).sum().item()\n",
    "\n",
    "#         # Print accuracy\n",
    "#         print('Accuracy for fold %d: %d %%' % (fold, 100.0 * correct / total))\n",
    "#         print('--------------------------------')\n",
    "#         results[fold] = 100.0 * (correct / total)\n",
    "    \n",
    "# Print fold results\n",
    "# print(f'K-FOLD CROSS VALIDATION RESULTS FOR {k_folds} FOLDS')\n",
    "# print('--------------------------------')\n",
    "# sum = 0.0\n",
    "# for key, value in results.items():\n",
    "#     print(f'Fold {key}: {value} %')\n",
    "#     sum += value\n",
    "# print(f'Average: {sum/len(results.items())} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test data 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, img_paths, transform):\n",
    "        self.img_paths = img_paths\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = Image.open(self.img_paths[index])\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12600/12600 [03:10<00:00, 66.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test inference is done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# meta 데이터와 이미지 경로를 불러옵니다.\n",
    "submission = pd.read_csv(os.path.join(test_dir, 'info.csv'))\n",
    "image_dir = os.path.join(test_dir, 'images')\n",
    "model_path = './denseNet_-fold-0.pth'\n",
    "\n",
    "# Test Dataset 클래스 객체를 생성하고 DataLoader를 만듭니다.\n",
    "image_paths = [os.path.join(image_dir, img_id) for img_id in submission.ImageID]\n",
    "transform = transforms.Compose([\n",
    "    Resize((512, 384), Image.BILINEAR),\n",
    "    ToTensor(),\n",
    "    Normalize(mean=(0.5, 0.5, 0.5), std=(0.2, 0.2, 0.2)),\n",
    "])\n",
    "dataset = TestDataset(image_paths, transform)\n",
    "\n",
    "loader = DataLoader(\n",
    "    dataset,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# 모델을 정의합니다. (학습한 모델이 있다면 torch.load로 모델을 불러주세요!)\n",
    "device = torch.device('cuda')\n",
    "# pretrained_model = MyPreTrainedModel().to(device)\n",
    "# pretrained_model.load_state_dict(torch.load(model_path))\n",
    "pretrained_model.eval()\n",
    "# model.eval()\n",
    "# cnn_model.eval()\n",
    "# C.eval()\n",
    "# print(1)\n",
    "\n",
    "# 모델이 테스트 데이터셋을 예측하고 결과를 저장합니다.\n",
    "all_predictions = []\n",
    "for images in tqdm.tqdm(loader):\n",
    "    with torch.no_grad():\n",
    "        # print(2)\n",
    "        images = images.to(device)\n",
    "        # pred = C(images)\n",
    "        # print(3)\n",
    "        pred = pretrained_model(images)\n",
    "        #pred = cnn_model(images)\n",
    "        # print(4)\n",
    "        pred = pred.argmax(dim=-1)\n",
    "        # print(pred)\n",
    "        # print(5)\n",
    "        all_predictions.extend(pred.cpu().numpy())\n",
    "submission['ans'] = all_predictions\n",
    "\n",
    "# 제출할 파일을 저장합니다.\n",
    "submission.to_csv(os.path.join(test_dir, 'submission.csv'), index=False)\n",
    "print('test inference is done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "del pretrained_model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}